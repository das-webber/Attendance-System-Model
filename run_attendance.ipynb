{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b515f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from joblib import load\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from config import FACE_ID_MODEL, LABEL_ENCODER, ATTENDANCE_FILE, START_TIME, END_TIME\n",
    "\n",
    "# Load face recognition model\n",
    "clf = load(FACE_ID_MODEL)\n",
    "le = load(LABEL_ENCODER)\n",
    "\n",
    "# Load emotion model\n",
    "with open(\"models/emotion_model_arch.json\", \"r\") as f:\n",
    "    emotion_model = model_from_json(f.read())\n",
    "emotion_model.load_weights(\"models/emotion_model_weights.h5\")\n",
    "\n",
    "EMOTIONS = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\n",
    "\n",
    "# Attendance dict\n",
    "attendance = {}\n",
    "\n",
    "def within_time_window():\n",
    "    now = datetime.now().strftime(\"%H:%M\")\n",
    "    return START_TIME <= now <= END_TIME\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes = face_recognition.face_locations(rgb, model=\"hog\")\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    for enc, box in zip(encodings, boxes):\n",
    "        preds = clf.predict([enc])\n",
    "        student_name = le.inverse_transform(preds)[0]\n",
    "\n",
    "        top, right, bottom, left = box\n",
    "        face_img = frame[top:bottom, left:right]\n",
    "        gray_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_face = cv2.resize(gray_face, (48,48))\n",
    "        gray_face = gray_face.astype(\"float\")/255.0\n",
    "        gray_face = np.expand_dims(gray_face, axis=(0,-1))\n",
    "\n",
    "        emotion_pred = emotion_model.predict(gray_face)\n",
    "        emotion_label = EMOTIONS[np.argmax(emotion_pred)]\n",
    "\n",
    "        if within_time_window():\n",
    "            attendance[student_name] = {\n",
    "                \"time\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "                \"emotion\": emotion_label,\n",
    "                \"status\": \"Present\"\n",
    "            }\n",
    "\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0,255,0), 2)\n",
    "        cv2.putText(frame, f\"{student_name} - {emotion_label}\", (left, top-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Attendance System\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save attendance\n",
    "if attendance:\n",
    "    df = pd.DataFrame.from_dict(attendance, orient=\"index\")\n",
    "    df.to_csv(ATTENDANCE_FILE, index_label=\"Student\")\n",
    "    print(f\"[OK] Attendance saved to {ATTENDANCE_FILE}\")\n",
    "else:\n",
    "    print(\"[INFO] No attendance recorded.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
